# üß™ Tipos de Pruebas de Software

Documentaci√≥n completa sobre los diferentes tipos de pruebas de software, incluyendo pruebas funcionales,
no funcionales, unitarias, sistema (End-to-End), aceptaci√≥n (UAT),
estrategias de pruebas, dise√±o de pruebas y datos, as√≠ como tambi√©n trabajando por √°reas espec√≠ficas,
recetas r√°pidas, plantillas √∫tiles y checklists express y finalmente recomendaciones por stack tecnol√≥gico.

## 0. Mapa r√°pido

- **Por nivel**: 
   
  - [Pruebas Unitarias](#11-pruebas-unitarias)
  
  - [Pruebas de Integraci√≥n](#12-pruebas-de-integraci√≥n)
  
  - [Pruebas de Sistema (End-to-End)](#13-pruebas-de-sistema-end-to-end)

- **Por objetivo**:
   
  - [Pruebas Funcionales](#21-pruebas-funcionales)
  
  - [Pruebas No Funcionales](#22-pruebas-no-funcionales)

- **Estrategia transversal**:
   
  - [Smoke/Sanity/Regresi√≥n](#31-smokesanityregresi√≥n)
  
  - [Exploratoria](#32-exploratoria-session-based)
  
  - [Basada en Riesgo](#33-basada-en-riesgo)
  
  - [CI/CD](#9-recomendaciones-por-stack-tecnol√≥gico-r√°pidas)
  
  - [Shift-Left/Shift-Right](#35-shift-left--shift-right)

## 1. Niveles de Prueba

### 1.1 Pruebas Unitarias
 
- **Qu√© validan**: funciones/m√©todos aislados.

- **Objetivo**: exactitud l√≥gica y manejo de bordes.

- **Tips**: usar mocks/stubs para dependencias, r√°pidas y deterministas.

- **Herramientas**: Jest, Vitest, PyTest, NUnit, JUnit, PHPUnit, etc.

### 1.2 Pruebas de Integraci√≥n

- **Qu√© validan**: interacci√≥n entre m√≥dulos (p. ej., API <-> DB).

- **Objetivo**: contratos y flujos entre componentes.

- **Tips**: base de datos temporal/contenerizada, test doubles de servicios externos.

### 1.3 Pruebas de Sistema (End-to-End)

- **Qu√© validan**: comportamiento del sistema completo (escenarios reales).

- **Objetivo**: que el flujo del usuario funcione de extremo a extremo.

- **Herramientas**: Cypress, Playwright, Selenium, TestCafe, etc.

### 1.4 Pruebas de Aceptaci√≥n (UAT)

- **Qu√© validan**: criterios de negocio con lenguaje claro.

- **Objetivo**: confirmar "lista para producci√≥n".

- **Pr√°ctica recomendada**: BDD con criterios Given-When-Then (Gherkin).

## 2. Por Objetivo

### 2.1 Pruebas Funcionales

- **Casos felices y de error**, validaciones de formularios, reglas de negocio, etc.

- **API Testing**: contratos HTTP, c√≥digos de estado, esquemas JSON, idempotencia, etc.

- **E2E web/m√≥vil**: flujos principales (login, compra, env√≠o de formulario, etc.).

### 2.2 Pruebas No Funcionales

#### 2.2.1 Rendimiento

- **Carga**: comportamiento bajo el uso esperado.

- **Estr√©s**: m√°s all√° del pico para encontrar el punto de ruptura.

- **Picos (Spike)**: r√°fagas cortas de alto tr√°fico.

- **Resistencia (Soak)**: estabilidad en periodos largos.

- **Escalabilidad**: rendimiento al aumentar recursos/usuarios.

- **Herramientas**: k6, Locust, JMeter, etc.

#### 2.2.2 Seguridad

- **SAST/DAST/SCA**: an√°lisis est√°tico/din√°mico, din√°mico y de dependencias.

- **Revisar**: OWASP Top 10 (inyecci√≥n, XSS, CSRF, auth rota, etc.).

- **Acciones r√°pidas**: sanitizar entradas, usar HTTPS, gestionar tokens/secretos, npm audit/pip-audit, OWASP ZAP Baseline, etc.

### 2.2.3 Usabilidad

- **Heur√≠sticas b√°sicas**: consistencia, feedback visible, prevenci√≥n de errores, etc.

- **Pruebas r√°pidas**: 5 minutos con 2-3 usuarios internos.

### 2.2.4 Accessibilidad

- **Referencia**: WCAG 2.2 AA.

- **Chequear**: navegaci√≥n por teclado, foco visible, texto alternativo, contraste, etc.

- **Herramientas**: Lighthouse, axe-core, WAVE, etc.

### 2.2.5 Compatibilidad

- **Navegadores/dispositivos clave**: define una **matriz m√≠nima** (ej. Chrome, Firefox, Safari, Edge, Android, iOS, etc).

- **Datos locales/timezones/idiomas**: validar formatos y RTL/LTR si aplica.

### 2.2.6 Localizaci√≥n/Internacionalizaci√≥n (i18n)

- **Validar**: longitudes de texto, monedas, traducciones, formatos de fecha/n√∫mero, separadores, pluralizaci√≥n, etc.

### 2.2.7 Confiabilidad/Resiliencia

- **Cortes controlados**: qu√© pasa si falla la red/servicio externo.

- **Reintentos y timeouts**: bien configurados.

## 3. Estrategias de Prueba

### 3.1 Smoke/Sanity/Regresi√≥n

- **Smoke**: lo m√≠nimo para ver si "respira" el build.

- **Sanity**: verificaci√≥n de cambios espec√≠ficos.

- **Regresi√≥n**: asegurar que lo viejo no se rompe con lo nuevo.

### 3.2 Exploratoria (Session-based)

- **Charters (misiones)** de 30-60 minutos, con objetivo, alcance y notas.

- Ideal para descubrir fallos no previstos.

### 3.3 Basada en Riesgo

- Priorizar probar **funcionalidades cr√≠ticas y de alto impacto** primero.

### 3.4 Pir√°mide de Pruebas

- Muchas **unitarias**, algunas **de integraci√≥n**, pocas **E2E** (r√°pidas y estables).

### 3.5 Shift-Left & Shift-Right

- **Shift-Left**: mover pruebas m√°s temprano en el ciclo de vida (desarrollo).

- **Shift-Right**: pruebas en producci√≥n, monitoreo y feedback post-lanzamiento

## 4. Dise√±o de Pruebas y Datos

### 4.1 T√©cnicas de Caja Negra

- **Partici√≥n de equivalencia** y **valores l√≠mite**.

- **Tablas de decisi√≥n** (combinaciones de reglas).

- **Transici√≥n de estados** (flujos con estados, ej. pedido).

**Ejemplo breve (l√≠mites):** campo edad (18-65):

- **Casos**:

  - V√°lidos: 18, 30, 65.
  
  - Inv√°lidos: 17, 66, -1, "texto".

### 4.2 T√©cnicas de Caja Blanca

- **Cobertura de c√≥digo**: sentencias, l√≠neas, ramas, condiciones, caminos, etc.

- Objetivo pr√°ctico: cobertura alta en m√≥dulos cr√≠ticos (calidad > porcentaje).

### 4.3 Gesti√≥n de Datos de Prueba

- **Fixtures/factories**, datos sint√©ticos, anonimizaci√≥n de PII.

- **Seeds** reproducibles para pruebas consistentes, limpiar entre tests.

- **Dobles de prueba**: mocks, stubs, fakes, spies, para servicios externos.

### 4.4 Entornos

- **Dev/Stage/Prod** con configuraciones esperadas.

- CI que ejecute: unitarias -> integraci√≥n -> smoke E2E -> (opcional) performance liviano.

## 5. √Åreas Espec√≠ficas

### 5.1 APIs

- Validar **contratos**, **c√≥digos** y **esquemas** (OpenAPI/JSON Schema).

- **Contrato entre servicios**: Pact (consumer/provider).

- **Herramientas**: Postman, Insomnia, Swagger UI, Dredd, etc.

### 5.2 Web

- **E2E**: Cypress/Playwright.

- **Componentes**: pruebas de UI por componente (Storybook test runner, Vitest + Testing Library).

- **Accesibilidad**: Lighthouse, axe-core en CI.

### 5.3 M√≥vil

- **UI funcional**: Appium, Detox.

- **Dispositivos reales o emuladores**, prioritarios seg√∫n la matriz objetivo.

### 5.4 Base de Datos

- **Integridad**: claves, constraints, migraciones.

- **Consultas cr√≠ticas**: tiempos y planes de ejecuci√≥n simples.

## 6. Recetas R√°pidas

### 6.1 Rendimiento con k6 (m√≠nimo viable)

```javascript
import http from 'k6/http';
import { sleep } from 'k6';

export const options = { vus: 10, duration: '1m' } // Carga ligera
export default function () {
    const res = http.get('https://tu-app.test/api/health');
    
    // Afirmaciones simples que se ven en c√≥digos de retorno
    sleep(1);
}
```
- **Objetivo**: detectar timeouts y endpoints lentos, no micro-optimizar.

### 6.2 BDD (Gherkin) de login

```gherkin
Feature: Login
  Scenario: Acceso exitoso con credenciales v√°lidas
    Given un usuario registrado
    When ingresa email y contrase√±a correctos
    Then ve el dashboard en menos de 2 segundos
```

### 7. Plantillas √∫tiles

### 7.1 Caso de Prueba (m√≠nimo)

```makefile
ID: TC-001
T√≠tulo: Login con credenciales v√°lidas
Precondiciones: Usuario registrado
Pasos:
  1) Abrir /login
  2) Ingresar email y password v√°lidos
  3) Presionar "Ingresar
Resultado esperado: Redirige al dashboard < 2s, sesi√≥n activa
Severidad si falla: Alta
Evidencias: capturas/logs
```

### 7.2 Charter exploratorio

```makefile
ID: TC-001
T√≠tulo: Login con credenciales v√°lidas
Precondiciones: Usuario registrado
Pasos:
  1) Abrir /login
  2) Ingresar email y password v√°lidos
  3) Presionar "Ingresar"
Resultado esperado: Redirige al dashboard < 2s, sesi√≥n activa
Severidad si falla: Alta
Evidencias: capturas/logs
```

### 7.3 Matriz de Pruebas (ejemplo)

| Funcionalidad  | Unit | Int | E2E | Perf | Sec | A11y |
|----------------|------|-----|-----|------|-----|------|
| Login          | ‚úÖ    | ‚úÖ   | ‚úÖ   | ‚ö™    | ‚ö™   | ‚ö™    |
| Perfil usuario | ‚úÖ    | ‚úÖ   | ‚ö™   | ‚ö™    | ‚ö™   | ‚ö™    |
| Pago           | ‚úÖ    | ‚úÖ   | ‚úÖ   | ‚úÖ    | ‚úÖ   | ‚ö™    |

(‚úÖ = aplicar, ‚ö™ = no aplica/pendiente)

## 8. Checklists Express (cuando hay poco tiempo)

- [ ] **Smoke** de rutas cr√≠ticas (abrir app, login, flujo principal).

- [ ] **Validaciones** de inputs (requeridos, formatos, l√≠mites).

- [ ] **Errores controlados** (404/500, mensajes claros).

- [ ] **Rendimiento b√°sico** (1‚Äì2 endpoints con k6/Locust).

- [ ] **A11y m√≠nima** (teclado, foco, contraste).

- [ ] **Seguridad b√°sica** (no secretos en repo, cabeceras, ZAP baseline si da el tiempo).

- [ ] **Regresi√≥n r√°pida** tras cada fix importante.

## 9. Recomendaciones por Stack Tecnol√≥gico (r√°pidas)

- JS/TS (Web): Jest + Testing Library; Cypress/Playwright; Lighthouse/axe; k6.

- Python (API): PyTest + requests; Locust/k6; OWASP ZAP; pytest-cov.

- Java/Kotlin (API): JUnit + REST Assured; Pact; JMeter/k6.

- Mobile: Appium; BrowserStack/Emuladores locales.